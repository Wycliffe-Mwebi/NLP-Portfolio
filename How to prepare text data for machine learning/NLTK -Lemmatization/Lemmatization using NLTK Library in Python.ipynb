{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e3c866",
   "metadata": {},
   "source": [
    "# Lemmatization using NLTK Library in Python\n",
    "### What is Lemmatization in NLP\n",
    "Lemmatization is the process of grouping together different inflected forms of words having the same root or lemma for better NLP analysis and operations. The lemmatization algorithm removes affixes from the inflected words to convert them into the base words (lemma form). For example, “running” and “runs” are converted to its lemma form “run”.\n",
    "\n",
    "Lemmatization looks similar to stemming initially but unlike stemming, lemmatization first understands the context of the word by analyzing the surrounding words and then convert them into lemma form. For example, the lemmatization of the word bicycles can either be bicycle or bicycle depending upon the use of the word in the sentence.\n",
    "\n",
    "### Why Lemmatization is used?\n",
    "Since Lemmatization converts words to their base form or lemma by removing affixes from the inflected words, it helps to create better NLP models like Bag of Word, TF-IDF that depend on the frequency of the words. At the same time, it also increases computational efficiency.\n",
    "\n",
    "### NLTK Lemmatization with WordNetLemmatizer\n",
    "Wordnet is a popular lexical database of the English language that is used by NLTK internally. WordNetLemmatizer is an NLTK lemmatizer built using the Wordnet database and is quite widely used.\n",
    "\n",
    "There is, however, one catch due to which NLTK lemmatization does not work and it troubles beginners a lot.\n",
    "\n",
    "The NLTK lemmatizer requires POS tag information to be provided explicitly otherwise it assumes POS to be a noun by default and the lemmatization will not give the right results.\n",
    "\n",
    "Let us understand all this with more examples.\n",
    "\n",
    "#### Examples of NLTK Lemmatization\n",
    "Here i will show you two sets of examples of lemmatization using WordNetLemmatizer without POS tags and with POS tags.\n",
    "\n",
    "###  1. WordNetLemmatizer() without POS tag\n",
    "In the two examples below, we first tokenize the text and then lemmatizes each token in for loop by using WordNetLemmatizer.lemmatize().\n",
    "\n",
    "However, we have used the default settings of the WordNetLemmatizer.lemmatize() and do not provide POS. Due to this, it assumes the default tag as noun ‘n’ internally and hence lemmatization does not work properly.\n",
    "\n",
    "In 1st example, the lemma returned for “Jumped” is “Jumped” and for “Breathed” it is “Breathed”. Similarly in the 2nd example, the lemma for “running” is returned as “running” only.\n",
    "\n",
    "Clearly, lemmatization is not working when we are not passing POS tags in the NLTK lemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec5ff9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She ---> She\n",
      "jumped ---> jumped\n",
      "into ---> into\n",
      "the ---> the\n",
      "river ---> river\n",
      "and ---> and\n",
      "breathed ---> breathed\n",
      "heavily ---> heavily\n"
     ]
    }
   ],
   "source": [
    "# example 1\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"She jumped into the river and breathed heavily\"\n",
    "wordnet = WordNetLemmatizer()\n",
    "tokenizer = word_tokenize(text)\n",
    "\n",
    "for token in tokenizer:\n",
    "    print(token,\"--->\",wordnet.lemmatize(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79442697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ---> I\n",
      "am ---> am\n",
      "running ---> running\n",
      "and ---> and\n",
      "I ---> I\n",
      "usually ---> usually\n",
      "use ---> use\n",
      "to ---> to\n",
      "runs ---> run\n"
     ]
    }
   ],
   "source": [
    "# example 2\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"I am running and I usually use to runs\"\n",
    "\n",
    "wordnet = WordNetLemmatizer()\n",
    "tokenizer = word_tokenize(text)\n",
    "\n",
    "for token in tokenizer:\n",
    "    print(token,\"--->\",wordnet.lemmatize(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7dee89",
   "metadata": {},
   "source": [
    "### 2. WordNetLemmatizer() with POS tags\n",
    "In the below examples, after tokenization, we have first derived the pos tags of each token and then passed both tokens and pos to WordNetLemmatizer.lemmatize().\n",
    "\n",
    "This time we can see that lemmatization is done properly for “jumped” as “jump”, “breathed” as “breathe” and “running” as “run”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec9dad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She ---> She\n",
      "jumped ---> jump\n",
      "into ---> into\n",
      "the ---> the\n",
      "river ---> river\n",
      "and ---> and\n",
      "breathed ---> breathe\n",
      "heavily ---> heavily\n"
     ]
    }
   ],
   "source": [
    "# example 1\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize,pos_tag\n",
    "\n",
    "text = \"She jumped into the river and breathed heavily\"\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "for token,tag in pos_tag(word_tokenize(text)):\n",
    "    pos=tag[0].lower()\n",
    "        \n",
    "    if pos not in ['a', 'r', 'n', 'v']:\n",
    "        pos='n'\n",
    "    \n",
    "    print(token,\"--->\",wordnet.lemmatize(token,pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2a0d5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ---> I\n",
      "am ---> be\n",
      "running ---> run\n",
      "and ---> and\n",
      "I ---> I\n",
      "usually ---> usually\n",
      "use ---> use\n",
      "to ---> to\n",
      "runs ---> run\n"
     ]
    }
   ],
   "source": [
    "# example 2\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize,pos_tag\n",
    "\n",
    "text = \"I am running and I usually use to runs\"\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "for token,tag in pos_tag(word_tokenize(text)):\n",
    "    pos=tag[0].lower()\n",
    "        \n",
    "    if pos not in ['a', 'r', 'n', 'v']:\n",
    "        pos='n'\n",
    "    \n",
    "    print(token,\"--->\",wordnet.lemmatize(token,pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d028a23",
   "metadata": {},
   "source": [
    "## Application of Lemmatization\n",
    "- Lemmatization is used to reduce text redundancy by converting words having the same meaning but different inflected forms to their base form.\n",
    "- The reduced word density of redundant text helps to create better NLP models that are efficient and also computationally fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13990d9",
   "metadata": {},
   "source": [
    "## Stemming vs Lemmatization\n",
    "Although both look quite similar there are key differences between Stemming vs Lemmatization –\n",
    "\n",
    "- The output of lemmatization is an actual word like Changing -> Change but stemming may not produce an actual English word like Changing -> Chang.\n",
    "\n",
    "\n",
    "- The stemming process just follows the step-by-step implementation of algorithms like SnowBall, Porter, etc. to derive the stem. Whereas lemmatization makes use of a lookup database like WordNet to derive lemma. For example, the lemmatization of “better” is “well” and this another word is derived as lemma as it looks up in the dictionary. But the stemming result will come as “better” only without a lookup. However, this lookup can at times slow down the lemmatization process.\n",
    "\n",
    "\n",
    "- Stemming does not take the context of the word into account, for example, “meeting” can be a verb or noun based on the context. But lemmatization does consider the context of the word before generating its lemma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8431bb",
   "metadata": {},
   "source": [
    "## Stemming vs Lemmatization Example\n",
    "In the example code below we first tokenize the text and then with the help of for loop stemmed the token with Snowball Stemmer and Porter Stemmer. At the same time, we also Lemmatize the text and convert it into a lemma with the help of Wordnet Lemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feffc36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word      Snowball Stemmer    Wordnet Lemmatizer            \n",
      "better    better              well                          \n",
      "Caring    care                Caring                        \n",
      "are       are                 be                            \n",
      "am        am                  be                            \n",
      "worse     wors                worse                         \n",
      "strugglingstruggl             struggle                      \n",
      "meeting   meet                meeting                       \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer,PorterStemmer,WordNetLemmatizer\n",
    "from nltk import word_tokenize,pos_tag\n",
    "\n",
    "snowball = SnowballStemmer(language='english')\n",
    "porter = PorterStemmer()\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "text = [\"better\",\"Caring\",\"are\",\"am\",\"worse\",\"struggling\",'meeting']\n",
    "print(\"{0:10}{1:20}{2:30}\".format(\"Word\",\"Snowball Stemmer\",\"Wordnet Lemmatizer\"))\n",
    "for token,tag in pos_tag(text):\n",
    "    \n",
    "    pos=tag[0].lower()\n",
    "    if pos not in ['a', 'r', 'n', 'v']:\n",
    "        pos='n'\n",
    "        \n",
    "    print(\"{0:10}{1:20}{2:30}\".format(token,snowball.stem(token),wordnet.lemmatize(token,pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9200754c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
