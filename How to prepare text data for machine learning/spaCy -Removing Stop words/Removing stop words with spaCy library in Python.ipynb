{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea258483",
   "metadata": {},
   "source": [
    "# Removing stop words with spaCy library in Python\n",
    "#### Introduction\n",
    "When working with text data in NLP, we usually have to preprocess our data before carrying out the main task.\n",
    "\n",
    "One common preprocessing step we take is removing stop words which is what I will be showing you in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ad22d",
   "metadata": {},
   "source": [
    "#### What are Stop Words\n",
    "In English vocabulary, there are many words like “I”, “the” and “you” that appear very frequently in the text but they do not add any valuable information for NLP operations and modeling. These words are called stopwords and they are almost always advised to be removed as part of text preprocessing.\n",
    "\n",
    "When we remove stopwords it reduces the size of the text corpus which increases the performance and robustness of the NLP model. But sometimes removing the stopwords may have an adverse effect if it changes the meaning of the sentence. For example, if we consider the example “This is not a good way to talk” which is a negative sentence. When we remove stopwords from this sentence it becomes a positive sentence: “good way talk”.\n",
    "\n",
    "While there is no universal list of stop words in NLP, many NLP libraries in Python provide their list. We can also decide to create our own list of stop words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80586877",
   "metadata": {},
   "source": [
    "#### spaCy Stop Words\n",
    "Here we will be using the list of stop words provided by the spaCy library, so we don’t have to write our own.\n",
    "\n",
    "However, before we can use these stopwords from the spaCy library, we need to download it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87529281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n",
      "{'within', 'either', 'call', 'nor', 'above', 'latterly', 'hence', 'becomes', 'almost', 'before', 'again', 'put', 'get', 'seems', 'anywhere', 'being', 'none', 'became', 'will', 'whoever', 'one', 'everyone', 'was', 'next', 'whatever', 'into', 'that', 'amongst', 'not', 'whom', 'ca', 'wherein', 'forty', 'and', 'but', 'below', 'see', 'hereafter', 'least', 'become', 'else', 'n’t', 'many', 'why', 'make', 'Farden', 'may', '’re', '’m', 'whereas', 'somewhere', 're', \"'m\", 'in', \"'re\", 'or', 'sixty', 'n‘t', \"'ve\", 'where', 'toward', 'last', 'nowhere', '‘m', 'however', 'whenever', 'mine', 'anyhow', 'further', 'himself', 'these', 'ten', 'up', 'herein', 'whereby', 'he', 'hereby', 'back', 'her', 'no', 'other', 'while', 'much', 'all', 'otherwise', '‘ll', 'about', 'sometimes', '‘ve', 'beyond', 'third', 'name', 'do', 'such', 'until', 'hereupon', '‘s', 'am', 'done', 'rather', 'others', 'same', 'i', 'regarding', 'our', 'your', 'amount', 'they', 'everything', 'have', 'yet', 'on', 'perhaps', 'always', 'them', 'mostly', 'thru', 'several', 'it', 'another', 'him', 'very', 'by', 'three', 'each', 'latter', 'yours', 'seemed', 'serious', '’ll', 'off', 'can', 'are', 'along', 'must', 'formerly', 'ours', 'four', 'behind', 'the', 'meanwhile', 'so', '’s', 'since', 'used', 'quite', 'their', 'enough', 'thereby', 'between', 'once', 'made', 'though', 'eight', 'had', 'because', 'twenty', 'fifteen', 'except', 'side', 'via', 'among', 'often', 'keep', 'few', 'with', \"'d\", 'for', 'part', 'neither', 'indeed', 'hers', 'could', 'just', 'together', 'here', 'both', 'Wycliffe', 'thence', 'front', 'which', 'did', 'namely', 'wherever', 'whole', 'noone', 'through', 'using', 'unless', 'how', 'less', '‘d', 'whither', 'thus', 'therein', 'ourselves', 'after', 'Afham', 'whereafter', 'only', 'various', \"'s\", 'a', 'therefore', 'under', 'afterwards', 'nine', 'throughout', 'to', 'full', 'would', 'during', 'an', 'myself', 'onto', 'five', 'you', 'anything', 'still', 'if', 'everywhere', 'of', 'moreover', 'fifty', 'thereupon', 'sometime', '’ve', 'six', 'its', 'doing', 'every', 'show', 'empty', 'been', '’d', 'herself', 'seem', 'nothing', 'around', 'should', 'itself', 'bottom', 'already', 'ever', 'upon', 'own', 'be', 'hundred', 'anyway', 'something', 'Mwebi', 'whose', 'former', 'she', 'down', 'top', 'yourselves', 'his', 'those', 'against', 'really', 'has', \"'ll\", 'across', 'might', 'also', 'twelve', 'never', 'someone', 'whether', 'move', \"n't\", 'towards', 'eleven', 'anyone', 'well', 'give', 'elsewhere', 'too', 'without', 'besides', 'at', 'seeming', 'take', 'now', 'due', 'although', 'alone', 'becoming', 'themselves', 'whence', 'whereupon', 'my_new_stopword', 'yourself', 'does', 'as', 'my', 'more', '‘re', 'per', 'even', 'thereafter', 'any', 'nevertheless', 'than', 'beside', 'out', 'nobody', 'we', 'me', 'please', 'first', 'from', 'then', 'over', 'most', 'say', 'beforehand', 'were', 'is', 'some', 'us', 'two', 'cannot', 'go', 'somehow', 'this', 'there'}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "#loading the english language small model of spacy\n",
    "en = spacy.load('en_core_web_sm')\n",
    "stopwords = en.Defaults.stop_words\n",
    "\n",
    "print(len(stopwords))\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bacb6a2",
   "metadata": {},
   "source": [
    "#### Checking if a word is Stopword\n",
    "We can check whether a word is a stopword or not by using the is_stop method of Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b75ea4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The True\n",
      "wedding False\n",
      "started False\n",
      "arrived False\n",
      "too True\n",
      "late False\n",
      ", False\n",
      "We True\n",
      "could True\n",
      "not True\n",
      "use False\n",
      "the True\n",
      "allocated False\n",
      "venue False\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"The wedding started arrived too late, We could not use the allocated venue\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469b1e5",
   "metadata": {},
   "source": [
    "#### Remove Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f19c747",
   "metadata": {},
   "source": [
    "First, we import the spacy library.\n",
    "2nd, we load the English language model of the Spacy object.\n",
    "3rd, we store the list of stopwords in a variable. \n",
    "4th, We create an empty list to store words that are not stopwords.\n",
    "\n",
    "Using a for loop that iterates over the text (that has been split on whitespace) we check whether the word is present in the stopword list, if not we append it in the list.\n",
    "\n",
    "At last, we join the list of words that don’t contain stopwords using the “join()” function, and thus we have a final output where all stopwords are removed from the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddb82f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text  :   Let me show how to remove stopwords using spacy library\n",
      "Text after removing stopwords  :    Let remove stopwords spacy library\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "#loading the english language small model of spacy\n",
    "en = spacy.load('en_core_web_sm')\n",
    "stopwords = en.Defaults.stop_words\n",
    "\n",
    "text = \" Let me show how to remove stopwords using spacy library\"\n",
    "\n",
    "lst=[]\n",
    "for token in text.split():\n",
    "    if token.lower() not in stopwords:    #checking whether the word is not \n",
    "        lst.append(token)                    #present in the stopword list.\n",
    "        \n",
    "#Join items in the list\n",
    "print(\"Original text  : \",text)\n",
    "print(\"Text after removing stopwords  :   \",' '.join(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab74990",
   "metadata": {},
   "source": [
    "#### Adding Stopwords to Default Spacy List\n",
    "By default, Spacy has 326 English stopwords, but at times you may like to add your own custom stopwords to the default list. I will show you how in the below example.\n",
    "\n",
    "To add a custom stopword in Spacy, we first load its English language model and use add() method to add stopwords.\n",
    "\n",
    "This code shows how to add a single stopword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c59794b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy    \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.Defaults.stop_words.add(\"my_new_stopword\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0a77bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To add several stopwords at once:\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.Defaults.stop_words |= {\"Wycliffe\",\"Mwebi\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe57338",
   "metadata": {},
   "source": [
    "#### Remove Stopwords from Default Spacy List\n",
    "There may be some scenarios where you will like to preserve some stopwords in your text. In this case, you may remove those stopwords from Spacy default list by the remove() method as shown in the below examples.\n",
    "\n",
    "To remove a single stopword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71c1b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.Defaults.stop_words.remove(\"if\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd3694eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove several stopwords at once:\n",
    "import spacy    \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.Defaults.stop_words -= {\"who\", \"when\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e1f907",
   "metadata": {},
   "source": [
    "#### Filtering Stopwords from Text File\n",
    "In the code below i will remove the stopwords from an entire text file using Spacy as explained above. The only difference is that i have imported the text using the Python file operation “with open()”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76cf9390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text\n",
      "Joseph Robinette Biden Jr. (born November 20, 1942) is an American politician who is the 46th and current president of the United States. A member of the Democratic Party, he previously served as the 47th vice president from 2009 to 2017 under President Barack Obama and represented Delaware in the United States Senate from 1973 to 2009. \n",
      "\n",
      "\n",
      "Text after removing stop words\n",
      "Joseph Robinette Biden Jr. (born November 20, 1942) American politician who 46th current president United States. member Democratic Party, previously served 47th vice president 2009 2017 President Barack Obama represented Delaware United States Senate 1973 2009.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "en = spacy.load('en_core_web_sm')\n",
    "stopwords = en.Defaults.stop_words\n",
    "\n",
    "with open(r\"C:\\Users\\user\\NLP\\biden.txt\", 'r', encoding= 'UTF-8') as f:\n",
    "    text=f.read()\n",
    "    \n",
    "lst=[]\n",
    "for token in text.split():\n",
    "    if token.lower() not in stopwords:\n",
    "        lst.append(token)\n",
    "\n",
    "print('Original Text')        \n",
    "print(text,'\\n\\n')\n",
    "\n",
    "print('Text after removing stop words')\n",
    "print(' '.join(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4553d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
