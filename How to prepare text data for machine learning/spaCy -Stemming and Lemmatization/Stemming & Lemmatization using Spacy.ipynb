{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6141b9c9",
   "metadata": {},
   "source": [
    "# Stemming & Lemmatization using Spacy\n",
    "Stemming is a process of converting the word to its base form.\n",
    "\n",
    "For example, converting the word “walking” to “walk”\n",
    "\n",
    "It just chops off the part of word by assuming that the result is the expected word. As this is done without any grammer based, sometimes, Stemming may go wrong.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b50d54",
   "metadata": {},
   "source": [
    "### SpaCy:\n",
    "SpaCy does not provide a built-in function for Stemming as Stemming is not accurate and SpaCy is mainly created for Production level use. Inaccurate process is not obviously not useful for Production.\n",
    "\n",
    "However it provides Lemmatization.\n",
    "\n",
    "<b>Lemmatization</b> does the same job but more accurately with the help of language specific dictionary and returns the exact root word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a286890e",
   "metadata": {},
   "source": [
    "### Steps to do Lemmatisation:\n",
    "1. Import SpaCy\n",
    "2. Load the trained Language Pipeline. This will contain all the components and data to process text.\n",
    "3. Passing the text to this trained pipeline will provides an object with all information about the text. Example: Tokens, Lemmas, Is_Stop word?, Parts Of Speech information etc.\n",
    "4. Iterate over the words and extract the Lemma values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5046aa53",
   "metadata": {},
   "source": [
    "#### Example #1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "969c7383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-->I\n",
      "have-->have\n",
      "been-->be\n",
      "sitting-->sit\n",
      "all-->all\n",
      "day-->day\n",
      ",-->,\n",
      "I-->I\n",
      "better-->well\n",
      "get-->get\n",
      "moving-->move\n",
      "now-->now\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    " \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('I have been sitting all day, I better get moving now')\n",
    " \n",
    "for token in doc:\n",
    "    print(token.text + \"-->\" + token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a3512",
   "metadata": {},
   "source": [
    "#### Example #3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb721004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The-->the\n",
      "brown-->brown\n",
      "foxes-->fox\n",
      "are-->be\n",
      "quick-->quick\n",
      "and-->and\n",
      "they-->they\n",
      "are-->be\n",
      "jumping-->jump\n",
      "over-->over\n",
      "the-->the\n",
      "sleeping-->sleep\n",
      "lazy-->lazy\n",
      "dogs-->dog\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    " \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(\"The brown foxes are quick and they are jumping over the sleeping lazy dogs\")\n",
    " \n",
    "for token in doc:\n",
    "    print(token.text + \"-->\" + token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8408ecd",
   "metadata": {},
   "source": [
    "#### Example #2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c797ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\t I \n",
      "came\t come \n",
      "in\t in \n",
      "and\t and \n",
      "met\t meet \n",
      "with\t with \n",
      "her\t her \n",
      "teammates\t teammate \n",
      "at\t at \n",
      "the\t the \n",
      "meeting\t meeting \n",
      ".\t . \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(\"I came in and met with her teammates at the meeting.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text}\\t {token.lemma_} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b53179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
