{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f03b72",
   "metadata": {},
   "source": [
    "# Removing stop words with NLTK library in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e9fc3",
   "metadata": {},
   "source": [
    "## Stop Words\n",
    "#### What are Stopwords?\n",
    "In English vocabulary, there are many words like “I”, “the” and “you” that appear very frequently in the text, But for purposes of for NLP operations and modeling, they do not add any valuable information. These words are called stopwords and they are almost always advised to be removed as part of text preprocessing.\n",
    "\n",
    "#### Why Remove stop words\n",
    "\n",
    "When we remove stopwords it reduces the size of the text corpus which increases the performance and robustness of the NLP model. But sometimes removing the stopwords may have an adverse effect if it changes the meaning of the sentence. For example, if we consider the example “This is not a good way to talk” which is a negative sentence. When we remove stopwords from this sentence it becomes a positive sentence: “good way talk”.\n",
    "\n",
    "While there is no universal list of stop words in NLP, many NLP libraries in Python provide their list. We can also decide to create our own list of stop words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf8ca5b",
   "metadata": {},
   "source": [
    "#### Stopwords in NLTK\n",
    "NLTK holds a built-in list of around 179 English Stopwords. The default list of these stopwords can be loaded by using stopwords.word() module of NLTK. This list can be modified as per our needs.\n",
    "\n",
    "A very common usage of stopwords.word() is in the text preprocessing phase or pipeline before actual NLP techniques like text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1932544b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download stopwords -NLTK\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55d839b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "print (stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e63cd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('french'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f25916",
   "metadata": {},
   "source": [
    "#### Remove Stopwords from Text\n",
    "Below, we will remove stopwords from a string with NLTK. \n",
    "\n",
    "- First we will create a “stopwords.word()” object with English vocabulary and store the list of stopwords in a variable. \n",
    "- Then we will create an empty list to store words that are not stopwords.\n",
    "\n",
    "Using a for loop that iterates over the text (that has been split on whitespace) we will check whether the word is present in the stopword list, if not we appended it in the list.\n",
    "\n",
    "At last, we join the list of words that don’t contain stopwords using “join()” function and thus we have a final output where all stopwords are removed from the string using the NLTK stopwords list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca5588b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spread love everywhere go. Let one ever come without leaving happier\n"
     ]
    }
   ],
   "source": [
    "# Example -1\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "text = \"Spread love everywhere you go. Let no one ever come to you without leaving happier\"\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "lst=[]\n",
    "for token in text.split():\n",
    "    if token.lower() not in en_stopwords:    #checking whether the word is not \n",
    "        lst.append(token)                    #present in the stopword list.\n",
    "        \n",
    "#Join items in the list\n",
    "print(' '.join(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd44e122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life happens busy making plans\n"
     ]
    }
   ],
   "source": [
    "# Example -2\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "text = \"Life is what happens when you're busy making other plans\"\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "lst=[]\n",
    "for token in text.split():\n",
    "    if token.lower() not in en_stopwords:\n",
    "        lst.append(token)\n",
    "        \n",
    "print(' '.join(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1196e0",
   "metadata": {},
   "source": [
    "### Adding Stop Words to Default NLTK Stopwords List\n",
    "There are 179 English stopwords however, we can add our own stopwords to the list of stopwords. To add a word to NLTK stop words list, we first create a list from the “stopwords.word(‘english’)” object. Next, we use the extend method on the list to add our list of words to the default stopwords list.\n",
    "\n",
    "#### Example\n",
    "The following script adds a list of words to the NLTK stop word collection. Initially, the length of words in stopwords.words(‘english’) object is 179 but on adding 3 more words the length of the list becomes 182."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb0eaccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_stopwords = stopwords.words('english')\n",
    "print(len(en_stopwords))\n",
    "new_stopwords = [\"you're\",\"i'll\",\"we'll\"]\n",
    "en_stopwords.extend(new_stopwords)\n",
    "len(en_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba46f2e5",
   "metadata": {},
   "source": [
    "### NLTK Stopwords for other Languages\n",
    "Other than English, NLTK supports these languages having stopwords. We can get the list of supported languages below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "560cec99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arabic', 'azerbaijani', 'basque', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebfa0a1",
   "metadata": {},
   "source": [
    "### Removing stopwords from Text File\n",
    "In the code below we have removed the stopwords in the same process as discussed above, the only difference is that we have imported the text by using the Python file operation “with open()”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d530188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text\n",
      "Joseph Robinette Biden Jr. (born November 20, 1942) is an American politician who is the 46th and current president of the United States. A member of the Democratic Party, he previously served as the 47th vice president from 2009 to 2017 under President Barack Obama and represented Delaware in the United States Senate from 1973 to 2009. \n",
      "\n",
      "\n",
      "Text after removing stop words\n",
      "Joseph Robinette Biden Jr. (born November 20, 1942) American politician 46th current president United States. member Democratic Party, previously served 47th vice president 2009 2017 President Barack Obama represented Delaware United States Senate 1973 2009.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "\n",
    "en_stopwords = stopwords.words('english') \n",
    "with open(r\"C:\\Users\\user\\NLP\\biden.txt\") as f:\n",
    "    text=f.read()\n",
    "    \n",
    "lst=[]\n",
    "for token in text.split():\n",
    "    if token.lower() not in en_stopwords:\n",
    "        lst.append(token)\n",
    "\n",
    "print('Original Text')        \n",
    "print(text,'\\n\\n')\n",
    "\n",
    "print('Text after removing stop words')\n",
    "print(' '.join(lst)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b11972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717eacdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
