{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c91bb5c",
   "metadata": {},
   "source": [
    "# Text Summarising of the articles\n",
    "## Text-Summarization\n",
    "Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document. Technologies that can make a coherent summary take into account variables such as length, writing style and syntax.\n",
    "\n",
    "Automatic data summarization is part of machine learning and data mining. The primary idea of summarization is to find a subset of data which contains the \"information\" of the entire set. Such techniques are widely used in industry today. Search engines are an example; others include summarization of documents, image collections and videos. Document summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images. For surveillance videos, one might want to extract the important events from the uneventful context.\n",
    "\n",
    "There are two general approaches to automatic summarization: Extraction and Abstraction.\n",
    "\n",
    "#### 1. Extractive Summarization: \n",
    "These methods rely on extracting several parts, such as phrases and sentences, from a piece of text and stack them together to create a summary. Therefore, identifying the right sentences for summarization is of utmost importance in an extractive method.\n",
    "\n",
    "\n",
    "#### 2. Abstractive Summarization: \n",
    "These methods use advanced NLP techniques to generate an entirely new summary. Some parts of this summary may not even appear in the original text. Such a summary might include verbal innovations. Research to date has focused primarily on extractive methods, which are appropriate for image collection summarization and video summarization.\n",
    "\n",
    "In this Jupyter notebook, TextRank algorithm for extractive text summarization is implemented using Google's PageRank search algorithm to generate corelations among sentences.\n",
    "\n",
    "#### Libraries Used\n",
    "- Numpy\n",
    "- Pandas\n",
    "- Natural Language Toolkit\n",
    "\n",
    "####  Algorithms and Concepts\n",
    "- TextRank\n",
    "- PageRank\n",
    "- Cosine Similarity\n",
    "\n",
    "### How to run\n",
    "- Install the required libraries using pip, virtual environment or conda.\n",
    "- Run jupyter notebook in your terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1e70e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt') # one time execution\n",
    "import re\n",
    "#nltk.download('stopwords') # one time execution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41a6bed",
   "metadata": {},
   "source": [
    "### Word embedding\n",
    "Word embedding is the technique to convert each word into an equivalent float vector. Various techniques exist depending on the use-case of the model and dataset. \n",
    "Example: \n",
    "\n",
    "'the': [-0.123, 0.353, 0.652, -0.232]\n",
    "\n",
    "\n",
    "'the' is very often used word in texts of any kind. its equivalent 4-dimension dense vector has been given.\n",
    "\n",
    "\n",
    "### Pretrained Word Embeddings for NLP\n",
    "Pretrained Word Embeddings are the embeddings learned in one task that are used for solving another similar task.\n",
    "\n",
    "These embeddings are trained on large datasets, saved, and then used for solving other tasks. That’s why pretrained word embeddings are a form of Transfer Learning.\n",
    "#### Google’s Word2vec \n",
    "-Word2Vec is trained on the Google News dataset (about 100 billion words).\n",
    "#### Stanford’s GloVe\n",
    "- It stands for Global Vectors. This is created by Stanford University. Glove has pre-defined dense vectors for around every 6 billion words of English literature along with many other general use characters like comma, braces, and semicolons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f4f663d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract word vectors\n",
    "word_embeddings = {}\n",
    "\n",
    "file = open(r'C:\\Users\\user\\NLP\\glove.6B.100d.txt', errors ='ignore', encoding ='utf-8')\n",
    "\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "file.close()\n",
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8d616",
   "metadata": {},
   "source": [
    "#### In this task, I will be summarising Medicine Descrptions provided in the file named  'TASK.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0a70d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file\n",
    "df = pd.read_excel(r'C:\\Users\\user\\NLP\\TASK.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "efa086d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEST DATASET</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Introduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Acnesol Gel is an antibiotic that fights bacte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ambrodil Syrup is used for treating various re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Augmentin 625 Duo Tablet is a penicillin-type ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Azithral 500 Tablet is an antibiotic used to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Azapure Tablet belongs to a group of medicines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Arimidex 1mg Tablet  is used alone or with oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Arpimune ME 100mg Capsule is used to prevent y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Amlodac CH Tablet is a combination medicine us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angizem CD 120 Capsule ER is used to treat ang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TEST DATASET                                         Unnamed: 1\n",
       "0              NaN                                       Introduction\n",
       "1              NaN  Acnesol Gel is an antibiotic that fights bacte...\n",
       "2              NaN  Ambrodil Syrup is used for treating various re...\n",
       "3              NaN  Augmentin 625 Duo Tablet is a penicillin-type ...\n",
       "4              NaN  Azithral 500 Tablet is an antibiotic used to t...\n",
       "...            ...                                                ...\n",
       "996            NaN  Azapure Tablet belongs to a group of medicines...\n",
       "997            NaN  Arimidex 1mg Tablet  is used alone or with oth...\n",
       "998            NaN  Arpimune ME 100mg Capsule is used to prevent y...\n",
       "999            NaN  Amlodac CH Tablet is a combination medicine us...\n",
       "1000           NaN  Angizem CD 120 Capsule ER is used to treat ang...\n",
       "\n",
       "[1001 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1548e2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TEST DATASET', 'Unnamed: 1'], dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc244922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEST DATASET</th>\n",
       "      <th>Introduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Acnesol Gel is an antibiotic that fights bacte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ambrodil Syrup is used for treating various re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Augmentin 625 Duo Tablet is a penicillin-type ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Azithral 500 Tablet is an antibiotic used to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Alkasol Oral Solution is a medicine used in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Azapure Tablet belongs to a group of medicines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Arimidex 1mg Tablet  is used alone or with oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Arpimune ME 100mg Capsule is used to prevent y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Amlodac CH Tablet is a combination medicine us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angizem CD 120 Capsule ER is used to treat ang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TEST DATASET                                       Introduction\n",
       "1              NaN  Acnesol Gel is an antibiotic that fights bacte...\n",
       "2              NaN  Ambrodil Syrup is used for treating various re...\n",
       "3              NaN  Augmentin 625 Duo Tablet is a penicillin-type ...\n",
       "4              NaN  Azithral 500 Tablet is an antibiotic used to t...\n",
       "5              NaN  Alkasol Oral Solution is a medicine used in th...\n",
       "...            ...                                                ...\n",
       "996            NaN  Azapure Tablet belongs to a group of medicines...\n",
       "997            NaN  Arimidex 1mg Tablet  is used alone or with oth...\n",
       "998            NaN  Arpimune ME 100mg Capsule is used to prevent y...\n",
       "999            NaN  Amlodac CH Tablet is a combination medicine us...\n",
       "1000           NaN  Angizem CD 120 Capsule ER is used to treat ang...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns = {'Unnamed: 1' : 'Introduction' }, inplace=True)\n",
    "# Deleting the first row\n",
    "df.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c33acc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acnesol Gel is an antibiotic that fights bacteria. It is used to treat acne, which appears as spots or pimples on your face, chest or back. This medicine works by attacking the bacteria that cause these pimples.Acnesol Gel is only meant for external use and should be used as advised by your doctor. You should normally wash and dry the affected area before applying a thin layer of the medicine. It should not be applied to broken or damaged skin. Avoid any contact with your eyes, nose, or mouth. Rinse it off with water if you accidentally get it in these areas. It may take several weeks for your symptoms to improve, but you should keep using this medicine regularly. Do not stop using it as soon as your acne starts to get better. Ask your doctor when you should stop treatment.Common side effects like minor itching, burning, or redness of the skin and oily skin may be seen in some people. These are usually temporary and resolve on their own. Consult your doctor if they bother you or do not go away.It is a safe medicine, but you should inform your doctor if you have any problems with your bowels (intestines). Also, inform the doctor if you have ever had bloody diarrhea caused by taking antibiotics or if you are using any other medicines to treat skin conditions. Consult your doctor about using this medicine if you are pregnant or breastfeeding.\n"
     ]
    }
   ],
   "source": [
    "# Converting the DataFrame into a dictionary\n",
    "text_dictionary = {}\n",
    "for i in range(1,len(df['TEST DATASET'])):\n",
    "    text_dictionary[i] = df['Introduction'][i]\n",
    "    \n",
    "print(text_dictionary[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1c139",
   "metadata": {},
   "source": [
    "#### There are 1000 such description of the different medicines. The task is to give summarised form of these description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "44b3c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove stopwords\n",
    "def remove_stopwords(sen):\n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06976702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make vectors out of the sentences\n",
    "def sentence_vector_func (sentences_cleaned) : \n",
    "    sentence_vector = []\n",
    "    for i in sentences_cleaned:\n",
    "        if len(i) != 0:\n",
    "            v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "        else:\n",
    "            v = np.zeros((100,))\n",
    "        sentence_vector.append(v)\n",
    "    \n",
    "    return (sentence_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a307f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the summary of the articles\n",
    "# NOTE - Remove '#' infront of print statement for displaying the contents at different stages of the text summarisation process\n",
    "def summary_text (test_text, n = 5):\n",
    "    sentences = []\n",
    "    \n",
    "    # tokenising the text \n",
    "    sentences.append(sent_tokenize(test_text))\n",
    "    #print(sentences)\n",
    "    sentences = [y for x in sentences for y in x] # flatten list\n",
    "    #print(sentences)\n",
    "    \n",
    "    # remove punctuations, numbers and special characters\n",
    "    clean_sentences = pd.Series(sentences).str.replace(\"[^a-z A-Z 0-9]\", \" \")\n",
    "\n",
    "    # make alphabets lowercase\n",
    "    clean_sentences = [s.lower() for s in clean_sentences]\n",
    "    #print(clean_sentences)\n",
    "\n",
    "    \n",
    "    # remove stopwords from the sentences\n",
    "    clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]\n",
    "    #print(clean_sentences)\n",
    "    \n",
    "    sentence_vectors = sentence_vector_func(clean_sentences)\n",
    "    \n",
    "    # similarity matrix\n",
    "    sim_mat = np.zeros([len(sentences), len(sentences)])\n",
    "    #print(sim_mat)\n",
    "    \n",
    "    # Finding the similarities between the sentences \n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j:\n",
    "                sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]\n",
    "    \n",
    "    \n",
    "    nx_graph = nx.from_numpy_array(sim_mat)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    #print(scores)\n",
    "    \n",
    "    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)))\n",
    "    # Extract sentences as the summary\n",
    "    summarised_string = ''\n",
    "    for i in range(n):\n",
    "        \n",
    "        try:\n",
    "            summarised_string = summarised_string + str(ranked_sentences[i][1])            \n",
    "        except IndexError:\n",
    "            print (\"Summary Not Available\")\n",
    "    \n",
    "    return (summarised_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802d5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kindly let me know in how many sentences you want the summary - \n"
     ]
    }
   ],
   "source": [
    "print(\"Kindly let me know in how many sentences you want the summary - \")\n",
    "x = int(input())\n",
    "\n",
    "summary_dictionary = {}\n",
    "\n",
    "for key in text_dictionary:\n",
    "    \n",
    "    para = text_dictionary[key]\n",
    "    print(\"Summary of the article - \",key)\n",
    "    summary = summary_text(para,x)\n",
    "    summary_dictionary[key] = summary\n",
    "    \n",
    "    print(summary)\n",
    "    print('='*120)    \n",
    "    \n",
    "print (\"*\"*40,\"The process has been completed successfully\",\"*\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df52ce04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ae8638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
